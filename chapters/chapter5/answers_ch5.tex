\documentclass[krantz1,ChapterTOCs]{krantz}
\usepackage{fixltx2e,fix-cm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{makeidx}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{xcolor}

\begin{document}

\begin{enumerate}
    \item Suppose that we collected a dataset with a single observation $\mathcal{D} = \{ 12 \}$. Please compute the probability of $\mathcal{D}$ if we assume our data was generated by a random variable $X$
    \begin{enumerate}
        \item Such that $X \sim \text{Geom}(p)$. Assume we know the parameter value $p$.
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align}
                    P(\mathcal{D} | p) = P(12 | p) =  p (1-p)^{12-1}
                \end{align}
            }
        \end{enumerate}
        
        \item Such that $X \sim \text{Pois}(\lambda)$. Assume we know the parameter value $\lambda$. 
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align}
                    P(\mathcal{D} | p) = P(12 | \lambda) = \frac{e^{-\lambda} \lambda^{12}}{12!}
                \end{align}
            }
        \end{enumerate}
 
        \item Such that $X \sim \mathcal{N}(\mu,\sigma^{2})$.
        Assume we know the parameter values $(\mu, \sigma^{2})$.
        
        \begin{enumerate}
            \item {\color{red}
            \begin{align*}
                    P(\mathcal{D} | \mu, \sigma^{2}) = P(12 | \mu, \sigma^{2})\\
                    &= \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp\left\{ -\frac{1}{2}\left( 12 - \mu\right)^{2}  / \sigma^{2}\right\}
                \end{align*}
            }
        \end{enumerate}
        
    \end{enumerate}
    
    \item Suppose that we collected a dataset with a two observations $\mathcal{D} = \{ 12, 2 \}$. Please compute the likelihood function for $\mathcal{D}$ if we assume our data was generated by a random variable $X$
        \begin{enumerate}
        \item Such that $X \sim \text{Geom}(p)$. Assume we know the parameter value $p$.
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | p) = P(12, 2 | p) &=  p (1-p)^{12-1} \cdot  p (1-p)^{2-1} \\ 
                    &= p^{2} (1-p)^{(12-1) + (2-1)}
                \end{align*}
            }
        \end{enumerate}
        
        \item Such that $X \sim \text{Pois}(\lambda)$ Assume we know the parameter value $\lambda$. 
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | \lambda) = P(12, 2 | \lambda) &=  \frac{e^{-\lambda} \lambda^{12}}{12!} \cdot  \frac{e^{-\lambda} \lambda^{2}}{2!} \\ 
                    &= \frac{ e^{-2\lambda} \lambda^{12 + 2} }{12! 2!}
                \end{align*}
            }
        \end{enumerate}
        
        \item Such that $X \sim \text{Binom}(20, \theta)$.
        Assume we know the parameter value $\theta$.
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | \lambda) = P(12, 2 | \theta) &= \binom{20}{12}\theta^{12}(1-\theta)^{8} \cdot  \binom{20}{2}\theta^{2}(1-\theta)^{18}\\
                    &= \binom{20}{12} \binom{20}{2} \theta^{12+2} (1-\theta)^{ 8+18}
                \end{align*}
            }
        \end{enumerate}
        
    \end{enumerate}
    
    \item Suppose that we collected a dataset with a $n$ observations $\mathcal{D} = \{ x_{1}, x_{2}, \cdots, x_{n} \}$. Please compute the log likelihood if we assume our data was generated by a random variable $X$
        \begin{enumerate}
        \item Such that $X \sim \text{Geom}(p)$. Assume we know the parameter value $p$.
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | p) &= P(x_{1},x_{2},\cdots,x_{n} | p)\\
                    &= P(x_{1}|p) \cdot P(x_{2}|p) \cdots P(x_{n}|p)\\
                    &= p(1-p)^{x_{1}-1} \cdot p(1-p)^{x_{2}-1} \cdots p(1-p)^{x_{n}-1} \\ 
                    &= p^{x_{1}+x_{2}+\cdots+x_{n}} (1-p)^{ (x_{1}-1) + (x_{2}-1) + \cdots + (x_{n}-1) } \\ 
                    &= p^{ \sum_{i=1}^{n} x_{i} } (1-p)^{ \sum_{i=1}^{n} (x_{i}-1) } \\ 
                    &= p^{ \sum_{i=1}^{n} x_{i} } (1-p)^{ \sum_{i=1}^{n} x_{i} - n } \\
                    \ell \ell (p) &= \sum_{i=1}^{n} x_{i} \log(p) + \left(\sum_{i=1}^{n} x_{i} - n\right) \log(1-p) 
                \end{align*}
            }
        \end{enumerate}
    
        \item Such that $X \sim \text{Pois}(\lambda)$ Assume we know the parameter value $\lambda$.
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | \lambda) &= P(x_{1},x_{2},\cdots,x_{n} | \lambda)\\
                    \mathcal{L}(\lambda) &= P(x_{1} | \lanbda) \cdot P(x_{n} | \lanbda) \cdots P(x_{n} | \lanbda) \\ 
                    \ell \ell (\lambda) &= \sum_{i=1}^{n} \log\left[ P(x_{i} | \lambda) \right] \\ 
                    &= \sum_{i=1}^{n} \log \left[ \frac{e^{-\lambda} \lambda^{x_{i}}}{x_{i}!}  \right] \\ 
                    &= \sum_{i=1}^{n} \log \left[ e^{-\lambda} \lambda^{x_{i}} \right] - \log(x_{i}!)\\
                    &= \sum_{i=1}^{n} \log \left(-\lambda\right) x_{i}\log(\lambda)  - \log(x_{i}!)\\
                    &= \sum_{i=1}^{n} -\log \left(\lambda\right) x_{i}\log(\lambda)  - \log(x_{i}!)\\
                \end{align*}
            }
        \end{enumerate}
        
        
        \item Such that $X \sim \text{Binom}(N, \theta)$.Assume we know the parameter value $\theta$.
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | \theta) &= P(x_{1},x_{2},\cdots,x_{n} | \theta)\\
                    \ell \ell (\theta) &= \sum_{i=1}^{n} \log\left[ P(x_{i} | \theta) \right] \\
                    \ell \ell (\theta) &= \log \left[ \binom{N}{x_{i}} \theta^{x_{i}} (1-\theta)^{20-x_{i}} \right] \\ 
                    \ell \ell (\theta) &= \log \left[ \binom{N}{x_{i}} \right] + x_{i} \log\left[\theta\right] + (20-x_{i})\log\left[1-\theta\right] \right] \\ 
                \end{align*}
            }
        \end{enumerate}
        
        \item Such that $X \sim \mathcal{N}(\mu,\sigma^{2})$.
        Assume we know the parameter values
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(\mathcal{D} | p) &= P(x_{1},x_{2},\cdots,x_{n} | p)\\
                    \ell \ell (\theta) &= \sum_{i=1}^{n} \log\left[ f(x_{i} | \theta) \right] \\
                    &= \sum_{i=1}^{n} \log\left\{ \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp\left[ -\frac{(x_{i} - \mu)^{2}}{2\sigma^{2}} \right]  \right\} \\ 
                    &= \sum_{i=1}^{n} \log\left( \frac{1}{\sqrt{2 \pi \sigma^{2}}} \right) - \frac{(x_{i} - \mu)^{2}}{2 \sigma^{2}} \\ 
                    &= \sum_{i=1}^{n} -\log\left( \sqrt{2 \pi \sigma^{2}} \right) - \frac{(x_{i} - \mu)^{2}}{2 \sigma^{2}} \\ 
                    &= \sum_{i=1}^{n} -\frac{1}{2}\log\left( 2 \pi \sigma^{2} \right) - \frac{(x_{i} - \mu)^{2}}{2 \sigma^{2}} \\ 
                    &=  -\frac{n}{2}\log\left( 2 \pi \sigma^{2} \right) - \sum_{i=1}^{n} \frac{(x_{i} - \mu)^{2}}{2 \sigma^{2}} \\ 
                \end{align*}
            }
        \end{enumerate}
        
    \end{enumerate}
    
    \item Suppose you collect a dataset $\mathcal{D} = (x_{1},x_{2},\cdots,x_{n})$ that you assume is generated from an i.i.d. sample $X_{1}, X_{2},\cdots, X_{n}$, where $X_{i} \sim f(x | \theta)$ and $\theta$ is a parameter.
    You decide to compute the loglikelihood
    \begin{align}
        \ell \ell (\theta | \mathcal{D}) = \sum_{i=1}^{n} \log \left [ f(x_{i} | \theta) \right]
    \end{align}
    Because we are interested in finding the value $\theta^{*}$ that maximizes $\mathcal{\ell \ell}$ then multiplying the log likelihood by a constant will not change the optimal $\theta^{*}$
    \begin{align}
        \frac{1}{n} \ell \ell (\theta | x_{1}, x_{2}, \cdots, x_{n}) = \frac{1}{n} \sum_{i=1}^{n} \log \left [ f(x_{i} | \theta) \right]
    \end{align}
    \begin{enumerate}
        \item The law of large numbers states that the above quantity will approach?
        
        \begin{enumerate}
            \item {\color{red}
                Because 
                \begin{align*}
                    \overline{X_{n}} \to \mathbb{E}(X)
                \end{align*}
                and because
                \begin{align*}
                    \overline{g(X)_{n}} \to \mathbb{E}(g(X))
                \end{align*}
                then we can recognize that $g(x_{i}) = \log\left[f(x_{i}| \theta) \right]$
                So then the above quantity will approach  
                \begin{align}
                    \mathbb{E}\left( \log\left[f(X| \theta) \right]\right)
                \end{align}
            }
        \end{enumerate}
        
    \end{enumerate}
    
    \item Suppose that we are asked to help better understand the burden of influenza circulating in in the state of Pennsylvania. 
    Over the course of 6 weeks we collect the following number of cases of reported influenza $\mathcal{D} = (143, 12, 124, 56, 66)$. 
    \begin{enumerate}
        \item Please propose a model for this data and a short description for why you chose this model. 
        
        \begin{enumerate}
            \item {\color{red} 
                Students can propose many models. Models that are \textbf{not} reasonable (i think) are Bernoulli, Normal. 
                \begin{align*}
                    (X_{1},X_{2},\cdots X_{n})\\
                    X_{i} \sim \text{Pois}(\lambda)
                \end{align*}
            }
        \end{enumerate}
        
        \item Please compute the likelihood for your model parameters given the data
        
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    P(143, 12, 124, 56, 66 | \lambda) &= \frac{e^{-\lambda} \lambda^{143}}{143!} \cdot \frac{e^{-\lambda} \lambda^{12}}{12!} \cdots \frac{e^{-\lambda} \lambda^{66}}{66!} 
                \end{align*}
        }
        \end{enumerate}
        \item Please compute the log likelihood.
        \begin{enumerate}
            \item {\color{red} 
                \begin{align*}
                    \log\left[P(143, 12, 124, 56, 66 | \lambda)\right] &= -\lambda + 143 \log(\lambda) - \log(143!)\\
                    &-\lambda + 12 \log(\lambda) - \log(12!) + \cdots +\\ &-\lambda + 66 \log(\lambda) - \log(66!)\\
                    &=-5\lambda + \log(\lambda)(143+12+\cdots+66)\\ 
                    &- (\log(143!) + \log(12!) + \cdots \log(66!) )\\
                    &= -5\lambda + \log(\lambda) 401 - (\log(143!) + \log(12!) + \cdots \log(66!) )
                \end{align*}
        }
        \end{enumerate}
        
    \item Consider the sequence $a_{n} = 2^{-n}$ for $n=1$ to $\infty$. 
    \begin{enumerate}
        \item Write down the first 3 items in this sequence 
        
        \begin{enumerate}
            \item  {\color{red} 1/2, 1/4, 1/8  }
        \end{enumerate}
        
        \item Please compute \[ \lim_{n \to \infty} a_{n} \]
        
        \begin{enumerate}
            \item  {\color{red} the limit is the value 0  }
        \end{enumerate}
        
        
    \end{enumerate}
    
    \item Does the infinite sequence $\{-1,1,-1,1,-1,1, \cdots \}$ have a limit? Why or why not? 
    
    \begin{enumerate}
            \item   {\color{red} No. This sequence does not have a limit because this sequence does not approach a single value. Instead, is oscillates. }
        \end{enumerate}
        
    
    \item Consider the finite sequence $a_{n} = 2^{-n}$ for $n=1$ to $100$, a sequence that ends at $2^{-100}$. 
    \begin{enumerate}
        \item Does this sequence have a limit point? Why or why not?
        \begin{enumerate}
            \item  {\color{red} No. This sequence does not have a limit because it is finite. The value 0 is a good candidate for a limit but the sequence cannot get any closer to 0 than 2^{-100} }
        \end{enumerate}
        
        
    \end{enumerate}
    
    \item Compute the derivative of 
    \begin{enumerate}
        \item $f(x) = e^{2x}$
        \begin{enumerate}
            \item  {\color{red} 
            \begin{align}
                f(x) = e^{h(x)} \\ 
                h(x) = 2x\\
                f' = e^{h(x)} (2x)' \\
                f' = e^{h(x)} 2 \\
                f' = 2e^{2x} 
            \end{align}
            }
        \end{enumerate}
        
        \item $f(x) = \log(\frac{1}{2x})$
        \begin{enumerate}
            \item  {\color{red}
            \begin{align}
                f(x) = \log(1/2x) \\ 
                f(x) = \log(h(x)) \\ 
                h(x) = 2x^{-1} \\
                f' = \frac{1}{h(x)} (2x^{-1})' \\
                f' = \frac{1}{h(x)} -1 (2x^{-2}) (2) \\
                f' = -\frac{1}{2x^{-1}} 2x^{-2} (2) \\
                f' = -\frac{2}{x} 
            \end{align}
            }
        \end{enumerate}
        
        \item $f(x) = x^{2} + e^{-x}$
        \begin{enumerate}
            \item  {\color{red} 
            \begin{align}
                f'(x) = 2x - e^{-x}
            \end{align}
            
            }
        \end{enumerate}
        
        \item $f(x) = 10$
        \begin{enumerate}
            \item  {\color{red} f'(x) = 0   }
        \end{enumerate}
        
        \item $f(x) = -3x$
        \begin{enumerate}
            \item  {\color{red}    f'(x) = - 3}
        \end{enumerate}
        
        \item $f(x) = \frac{1}{2}x^{2}$
        \begin{enumerate}
            \item  {\color{red}
                f'(x) = x
            }
        \end{enumerate}
        
        \item $f(x) = \log(x)$
        \begin{enumerate}
            \item  {\color{red}  $ f'(x) = \frac{1}{x}$ }
        \end{enumerate}
        \item $f(x) = \log(x^{2})$
        \begin{enumerate}
            \item  {\color{red} 
            f'(x) = \log(x^{2}) 2x
            
            
            }
        \end{enumerate}
        
        \item $f(x) = \log(10)$
        \begin{enumerate}
            \item  {\color{red}  f'(x) = 0    }
        \end{enumerate}
        
    \end{enumerate}
    
    \item  Assume a set of random variables $Z_{1}, Z_{2}, \cdots, Z_{n}$ such that $Z_{i} \sim \text{exp}(\beta)$ generated an observed dataset. An exponential distribution assign a density over continuous numbers from 0 to infinity. The probability density function is 
    \begin{align*}
        f(z) = \beta e^{-\beta z}     
    \end{align*}
    Suppose we collect a dataset $\mathcal{D} = (2,4,0.5,3)$.
    \begin{enumerate}
        \item Please compute the log likelihood of an arbitrary dataset $\mathcal{D} = (z_{1},z_{2},z_{3}\cdots,z_{n})$
        \begin{enumerate}
            \item {\color{red}
            \begin{align*}
                \ell \ell(\beta) = \log \left \[ p(z_{1},z_{2},\cdots,z_{n}) \r] \\ 
                \ell \ell(\beta) = \log(p(z_{1})+ + \log(p(z_{2})) + \cdots + \log( p(z_{n})) \\ 
                 \ell \ell(\beta) = \log(\beta e^{-\beta z_{1}}) + log(\beta e^{-\beta z_{2}}) + \cdots +  \log(\beta e^{-\beta z_{n}}) \\ 
                 \ell \ell(\beta) = \log(\beta) -\beta z_{1} +  \log(\beta) -\beta z_{2} + \cdots + \log(\beta) -\beta z_{n} \\
                 \ell \ell(\beta) = n\log(\beta) - \beta \sum_{i=1}^{n} z_{i}\\
            \end{align*}
            }
        \end{enumerate}
        
        \item Compute the derivative of the log likelihood above
        \begin{enumerate}
            \item  {\color{red}
            \ell \ell(\beta) = n\log(\beta) - \beta \sum_{i=1}^{n} z_{i}\\
            \ell \ell(\beta)' = \frac{n}{\beta} - \sum_{i=1}^{n} z_{i}
            }
        \end{enumerate}
        
        \item Set the derivative of the log likelihood equal to zero and solve for 
        $\beta$ (ie find the parameter value that maximizes the log likelhiood). 
        \begin{enumerate}
            \item  {\color{red} 
            \begin{align}
            \frac{n}{\beta} - \sum_{i=1}^{n} z_{i} = 0\\
            \frac{n}{\beta}  = \sum_{i=1}^{n} z_{i}\\
            \frac{\beta}{n}  = \frac{1}{\sum_{i=1}^{n} z_{i}}\\
            \beta = \frac{n}{\sum_{i=1}^{n} z_{i}}
            \end{align}
            }
        \end{enumerate}
        
        \item Apply the maximum likelihood estimate you found to the dataset  $\mathcal{D} = (2,4,0.5,3)$.
        \begin{enumerate}
            \item  {\color{red}$\hat{\beta} = 4/9.5 = 0.42$}
        \end{enumerate}
        
    \end{enumerate}
 
    
        
    \end{enumerate}
    
    
    
    
    
    
    
    
    
    
\end{document}